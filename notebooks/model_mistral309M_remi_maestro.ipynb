{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf840ed1-8345-4f30-b7b2-b57a8ab3f4f7",
   "metadata": {},
   "source": [
    "# Model Mistral + REMI + Maestro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a016b9-c988-440d-8f29-76faab1835ab",
   "metadata": {},
   "source": [
    "First baseline model using a Mistral transformer and REMI tokenizer, inspired by https://github.com/Natooz/MidiTok/blob/main/colab-notebooks/Example_HuggingFace_Mistral_Transformer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-07T18:15:46.116891Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from evaluate import load as load_metric\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.data_augmentation import augment_dataset\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "from miditok.utils import split_files_for_training\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import argmax\n",
    "from torch.cuda import is_available as cuda_available, is_bf16_supported\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, MistralConfig, Trainer, TrainingArguments, GenerationConfig\n",
    "from transformers.trainer_utils import set_seed\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8d828b-9827-4698-ac13-f777a8d76656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "mistral-309M_remi_maestro_v1\n"
     ]
    }
   ],
   "source": [
    "TRANSFORMER_NAME = \"mistral-309M\"\n",
    "TOKENIZER_NAME = \"remi\"\n",
    "DATASET_NAME = \"maestro\"\n",
    "MODEL_VERSION = \"1\"\n",
    "\n",
    "MODEL_NAME = f\"{TRANSFORMER_NAME}_{TOKENIZER_NAME}_{DATASET_NAME}_v{MODEL_VERSION}\"\n",
    "\n",
    "print(f\"Model:\\n{MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c727f80-2c70-4f67-8414-0d592a580afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\".\")\n",
    "#BASE_PATH = Path(\"/hpcwork/lect0148\")\n",
    "\n",
    "DATA_RAW_PATH = BASE_PATH / \"data\"\n",
    "\n",
    "MODEL_BASE_PATH = BASE_PATH / \"models\" / MODEL_NAME\n",
    "DATA_PROCESSED_PATH = MODEL_BASE_PATH / \"data_processed\"\n",
    "MODEL_PATH = MODEL_BASE_PATH / \"model\"\n",
    "RUNS_PATH = MODEL_BASE_PATH / \"runs\"\n",
    "OUTPUT_PATH = MODEL_BASE_PATH / \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67890f1c-c56d-4800-b956-763782791f11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T11:18:39.722714Z",
     "start_time": "2025-05-12T11:18:39.190892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnico-bremes\u001b[0m (\u001b[33mjonathanlehmkuhl-rwth-aachen-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_ENTITY\"] = \"jonathanlehmkuhl-rwth-aachen-university\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"piano-transformer\"\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b071044b71655bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 222\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c81a7b74-c026-47d3-8fe5-66afbe3b9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "maestro_files = list((DATA_RAW_PATH / \"maestro\").resolve().glob(\"**/*.midi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba59ce-0722-42ab-9a49-590bb972f4a0",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca9ec777-a003-4e50-9561-9d1989719f7f",
   "metadata": {},
   "source": [
    "tokenizer_config = TokenizerConfig(\n",
    "    pitch_range=(21, 109),\n",
    "    beat_res={(0, 1): 12, (1, 4): 8, (4, 12): 4}\n",
    "    special_tokens=[\"PAD\", \"BOS\", \"EOS\"],\n",
    "    use_chords=True,\n",
    "    use_rests=True,\n",
    "    use_tempos=True,\n",
    "    use_time_signatures=True,\n",
    "    use_sustain_pedals=True,\n",
    "    num_velocities=16,\n",
    "    num_tempos=32,\n",
    "    tempo_range=(50, 200),\n",
    ")\n",
    "tokenizer = REMI(tokenizer_config)\n",
    "\n",
    "# TODO: train/test split already here?\n",
    "tokenizer.train(vocab_size=30000, files_paths=maestro_files)\n",
    "tokenizer.save(MODEL_BASE_PATH / \"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f010d255-0ca1-40b2-b90b-ab4c3bfc2e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = REMI(params=MODEL_BASE_PATH / \"tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298a47bf-25c7-4c6b-ba5f-b3637f32fa79",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327886f8-255f-4419-9f3d-43349c8adf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/validation/test datasets\n",
    "midi_files_train, midi_files_temp = train_test_split(maestro_files, test_size=0.3, random_state=SEED)\n",
    "midi_files_valid, midi_files_test = train_test_split(midi_files_temp, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4aba630-21ff-4835-a120-905aabe85c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting music files (models/mistral-309M_remi_maestro_v1/data_processed/maestro_train):  80%|███████▉  | 712/893 [00:13<00:03, 51.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m midi_files, subset_name \u001b[38;5;129;01min\u001b[39;00m ((midi_files_train, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m), (midi_files_valid, \u001b[33m\"\u001b[39m\u001b[33mvalid\u001b[39m\u001b[33m\"\u001b[39m), (midi_files_test, \u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m      3\u001b[39m     subset_chunks_dir = Path(DATA_PROCESSED_PATH / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmaestro_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43msplit_files_for_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmidi_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset_chunks_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# TODO\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_overlap_bars\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/nico/Data/Entwicklung/piano-transformer/.venv/lib/python3.11/site-packages/miditok/utils/split.py:156\u001b[39m, in \u001b[36msplit_files_for_training\u001b[39m\u001b[34m(files_paths, tokenizer, save_dir, max_seq_len, average_num_tokens_per_note, num_overlap_bars, min_seq_len)\u001b[39m\n\u001b[32m    154\u001b[39m saving_path.parent.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file_path.suffix \u001b[38;5;129;01min\u001b[39;00m MIDI_FILES_EXTENSIONS:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[43mchunk_to_save\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaving_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    158\u001b[39m     chunk_to_save.dump_abc(saving_path)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Split MIDIs into smaller chunks that approximately matches the token sequence length for training\n",
    "for midi_files, subset_name in ((midi_files_train, \"train\"), (midi_files_valid, \"valid\"), (midi_files_test, \"test\")):\n",
    "    subset_chunks_dir = Path(DATA_PROCESSED_PATH / f\"maestro_{subset_name}\")\n",
    "    split_files_for_training(\n",
    "        files_paths=midi_files,\n",
    "        tokenizer=tokenizer,\n",
    "        save_dir=subset_chunks_dir,\n",
    "        max_seq_len=2048,\n",
    "        num_overlap_bars=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30faca34-cf20-49be-974c-ba95948be19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment training data set\n",
    "augment_dataset(\n",
    "    Path(DATA_PROCESSED_PATH / \"maestro_train\"),\n",
    "    pitch_offsets=[-12, 12],\n",
    "    velocity_offsets=[-4, 4],\n",
    "    duration_offsets=[-0.5, 0.5],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272902a-6c40-4f9a-bca9-b78a43769930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pytorch datasets\n",
    "midi_files_train = list((DATA_PROCESSED_PATH / \"maestro_train\").glob(\"**/*.midi\"))\n",
    "midi_files_valid = list((DATA_PROCESSED_PATH / \"maestro_valid\").glob(\"**/*.midi\"))\n",
    "midi_files_test = list((DATA_PROCESSED_PATH / \"maestro_train\").glob(\"**/*.midi\"))\n",
    "\n",
    "dataset_kwargs = {\n",
    "    \"max_seq_len\": 2048,\n",
    "    \"tokenizer\": tokenizer,\n",
    "    \"bos_token_id\": tokenizer[\"BOS_None\"],\n",
    "    \"eos_token_id\": tokenizer[\"EOS_None\"]\n",
    "}\n",
    "dataset_train = DatasetMIDI(midi_files_train, **dataset_kwargs)\n",
    "dataset_valid = DatasetMIDI(midi_files_valid, **dataset_kwargs)\n",
    "dataset_test = DatasetMIDI(midi_files_test, **dataset_kwargs)\n",
    "\n",
    "collator = DataCollator(tokenizer[\"PAD_None\"], copy_inputs_as_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7b5e8-1809-4a88-bfd1-668dbd5c4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(midi_files_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb218c-9ead-4c2d-b9e5-28c0bfcd1f06",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e20e7564-6d9c-48c0-9c94-0fbf754037de",
   "metadata": {},
   "source": [
    "model_config = MistralConfig(\n",
    "    vocab_size=len(tokenizer),\n",
    "    hidden_size=512,\n",
    "    intermediate_size=2048,\n",
    "    num_hidden_layers=8,\n",
    "    num_attention_heads=8,\n",
    "    num_key_value_heads=4,\n",
    "    sliding_window=256,\n",
    "    max_position_embeddings=8192,\n",
    "    pad_token_id=tokenizer[\"PAD_None\"],\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "model = AutoModelForCausalLM.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091ebb7a-9e52-4ee3-9b0c-be78d201e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = MistralConfig(\n",
    "    vocab_size=len(tokenizer),\n",
    "    hidden_size=896,\n",
    "    intermediate_size=896 * 4,\n",
    "    num_hidden_layers=24,\n",
    "    num_attention_heads=14,\n",
    "    num_key_value_heads=14,\n",
    "    sliding_window=2048,\n",
    "    max_position_embeddings=2048,\n",
    "    pad_token_id=tokenizer[\"PAD_None\"],\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "model = AutoModelForCausalLM.from_config(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488a1d2-48bc-4f4f-8db6-f436bc3df945",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeec9d0-9b5e-45df-90e4-4b68e15510e3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea34911-0e8c-4b73-92ac-6085161002b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits(logits, _):\n",
    "    pred_ids = argmax(logits, dim=-1)\n",
    "    return pred_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f809e9e-c3c1-45d2-b6a1-a8135021b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = cuda_available()\n",
    "if not cuda_available():\n",
    "    FP16 = FP16_EVAL = BF16 = BF16_EVAL = False\n",
    "elif is_bf16_supported():\n",
    "    BF16 = BF16_EVAL = True\n",
    "    FP16 = FP16_EVAL = False\n",
    "else:\n",
    "    BF16 = BF16_EVAL = False\n",
    "    FP16 = FP16_EVAL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25523906-e13a-4603-b698-5462ed521bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = TrainingArguments(\n",
    "    output_dir=RUNS_PATH,\n",
    "    overwrite_output_dir=False,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    do_predict=False,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    eval_accumulation_steps=None,\n",
    "    #eval_steps=5,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=0.01,\n",
    "    max_grad_norm=3.0,\n",
    "    #max_steps=5,\n",
    "    num_train_epochs=20,\n",
    "    lr_scheduler_type=\"cosine_with_restarts\",\n",
    "    warmup_ratio=0.3,\n",
    "    log_level=\"debug\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,\n",
    "    save_strategy=\"epoch\",\n",
    "    #save_steps=5,\n",
    "    #save_total_limit=5,\n",
    "    no_cuda=not USE_CUDA,\n",
    "    seed=SEED,\n",
    "    fp16=FP16,\n",
    "    fp16_full_eval=FP16_EVAL,\n",
    "    bf16=BF16,\n",
    "    bf16_full_eval=BF16_EVAL,\n",
    "    load_best_model_at_end=True,\n",
    "    label_smoothing_factor=0.,\n",
    "    optim=\"adamw_torch\",\n",
    "    report_to=[\"wandb\"],\n",
    "    run_name=MODEL_NAME,\n",
    "    gradient_checkpointing=True,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainer_config,\n",
    "    data_collator=collator,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_valid,\n",
    "    test_dataset=dataset_test,\n",
    "    #compute_metrics=compute_metrics,\n",
    "    callbacks=None,\n",
    "    preprocess_logits_for_metrics=preprocess_logits,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64afd6e-2be3-4431-9fb7-61224b9d5bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()\n",
    "trainer.save_model(MODEL_PATH)\n",
    "trainer.log_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_metrics(\"train\", train_result.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017e284-b7d1-4e23-a41c-51dbbe5145cf",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79d7de-b9d2-440e-8cb9-fb6320e4820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ee7d9-7a82-4dfb-83c5-7a17d3618e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=200,  # extends samples by 200 tokens\n",
    "    num_beams=1,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    top_k=15,\n",
    "    top_p=0.95,\n",
    "    epsilon_cutoff=3e-4,\n",
    "    eta_cutoff=1e-3,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Here the sequences are padded to the left, so that the last token along the time dimension\n",
    "# is always the last token of each seq, allowing to efficiently generate by batch\n",
    "collator.pad_on_left = True\n",
    "collator.eos_token = None\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d28fa-3a89-4721-8f4a-2d24a53dbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(dataset, output):\n",
    "    (output_path := Path(output)).mkdir(parents=True, exist_ok=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, collate_fn=collator)\n",
    "    \n",
    "    count = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Generating outputs\"):\n",
    "        res = model.generate(\n",
    "            inputs=batch[\"input_ids\"].to(model.device),\n",
    "            attention_mask=batch[\"attention_mask\"].to(model.device),\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "    \n",
    "        # Saves the generated music, as MIDI files and tokens (json)\n",
    "        for prompt, continuation in zip(batch[\"input_ids\"], res):\n",
    "            generated = continuation[len(prompt):]\n",
    "            tokens = [generated, prompt, continuation]\n",
    "            tokens = [seq.tolist() for seq in tokens]\n",
    "\n",
    "            midi_generated = tokenizer.decode([deepcopy(tokens[0])])\n",
    "            midi_prompt = tokenizer.decode([deepcopy(tokens[1])])\n",
    "            midi_full = tokenizer.decode([deepcopy(tokens[2])])\n",
    "\n",
    "            # Name the tracks\n",
    "            if midi_generated.tracks:\n",
    "                midi_generated.tracks[0].name = f\"Generated continuation ({len(tokens[0])} tokens)\"\n",
    "            if midi_prompt.tracks:\n",
    "                midi_prompt.tracks[0].name = f\"Original prompt ({len(tokens[1])} tokens)\"\n",
    "            if midi_full.tracks:\n",
    "                midi_full.tracks[0].name = f\"Full sequence ({len(tokens[2])} tokens)\"\n",
    "\n",
    "            # Save each as a separate MIDI file\n",
    "            midi_generated.dump_midi(output_path / f\"{count}_generated.midi\")\n",
    "            midi_prompt.dump_midi(output_path / f\"{count}_prompt.midi\")\n",
    "            midi_full.dump_midi(output_path / f\"{count}_full.midi\")\n",
    "            tokenizer.save_tokens(tokens, output_path / f\"{count}.json\")\n",
    "    \n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83091e-43d9-4e49-ba22-7e481f2b1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(dataset_test, OUTPUT_PATH / \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8de05-0295-439a-b278-291dbe231be4",
   "metadata": {},
   "source": [
    "## Convert to WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d2d9b-47fc-42f0-b459-f8c0db84c07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soundfont_path = \"FluidR3_GM.sf2\"\n",
    "midi_folder = OUTPUT_PATH / \"test\"\n",
    "output_folder = OUTPUT_PATH / \"test_wav\"\n",
    "\n",
    "for filename in os.listdir(midi_folder):\n",
    "    if filename.lower().endswith(\".midi\"):\n",
    "        midi_path = os.path.join(midi_folder, filename)\n",
    "        wav_filename = os.path.splitext(filename)[0] + \".wav\"\n",
    "        wav_path = os.path.join(output_folder, wav_filename)\n",
    "        \n",
    "        print(f\"Converting {filename} to {wav_filename}...\")\n",
    "        \n",
    "        # Build FluidSynth command\n",
    "        command = [\n",
    "            \"fluidsynth\",\n",
    "            \"-ni\",  # no interactive mode\n",
    "            soundfont_path,\n",
    "            midi_path,\n",
    "            \"-F\", wav_path,  # output file\n",
    "            \"-r\", \"44100\"    # sample rate\n",
    "        ]\n",
    "        \n",
    "        subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede8432-20cb-4d02-933a-17eae39f181d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
