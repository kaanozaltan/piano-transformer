{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf840ed1-8345-4f30-b7b2-b57a8ab3f4f7",
   "metadata": {},
   "source": [
    "# Model Mistral + REMI + Maestro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a016b9-c988-440d-8f29-76faab1835ab",
   "metadata": {},
   "source": [
    "First baseline model using a Mistral transformer and REMI tokenizer, inspired by https://github.com/Natooz/MidiTok/blob/main/colab-notebooks/Example_HuggingFace_Mistral_Transformer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42ce78",
   "metadata": {},
   "source": [
    "**Model name:** mistral162M_remi_maestro  \n",
    "**Previous version:** mistral309M_remi_maestro  \n",
    "**Changes:**\n",
    "- reduce model size to 162M\n",
    "- increase MLP dimension to 8x embedding dimension instead of the usual 4x rule - to allow learning more complex temporal dependencies that are present in music but not in language\n",
    "- increase max_position_embeddings back to 8192 to allow for extrapolation to longer sequences\n",
    "- decreasing gradient_accumulation_steps from 3 to 1 - as we already increased the batch size from 16 to our desired 64 we don't need to simulate higher batch sizes\n",
    "- set gradient_checkpointing to False as this slows down the training run while saving memory - if we run out of memory we can set it to True again\n",
    "- set warmup_ratio from 30% to 3% as it was unreasonably high, only wasting compute\n",
    "- set a min_lr ratio of 0.1 instead of none to not waste so much compute at the end of cosine schedule\n",
    "- in the tokenizer change num_velocities and tempo_range to the default values as it seemed otherwise a bit random\n",
    "- replace offline augmentation by on-the-fly augmentation and introduce much more variety in data augmentation -> will better mitigate overfitting, the model will see a wider variety of data\n",
    "  -> but number of examples per epoch is decreasing, so number of epochs should be increased\n",
    "- add tempo change data augmentation and overall reasonable and tested values for the different augmentation axes\n",
    "- increase train epochs from 20 to 1000. 20 epochs were not enough and we have decreased the number of example per epoch by 9, as we use early stopping we can increase this very much\n",
    "- introduce early stopping with a conservative patience of 10\n",
    "- set attention_dropout of 0.1 to reduce risk of overfitting. hidden_dropout (dropout in the feedforward layers) is not easily possible with mistral as the Llama architecture is not intended for this\n",
    "- use recommended train/valid/test split to ensure duplicate pieces are in the same set\n",
    "- use only train set for tokenization to avoid leakage\n",
    "- increase num_overlap_bars for chunking from 2 to 16 for better data utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182e87ca",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import wandb\n",
    "import tqdm\n",
    "from transformers.trainer_utils import set_seed\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from piano_transformer.config import load_config\n",
    "from piano_transformer.datasets.dataset import build_collator, build_datasets\n",
    "from piano_transformer.datasets.preprocessing import split_datasets_into_chunks\n",
    "from piano_transformer.model import build_mistral_model\n",
    "from piano_transformer.tokenizer import create_remi_tokenizer\n",
    "from piano_transformer.trainer import make_trainer\n",
    "from piano_transformer.midi import get_midi_file_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75c3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "mistral-162M_remi_maestro_v1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mjonathanlehmkuhl\u001B[0m (\u001B[33mjonathanlehmkuhl-rwth-aachen-university\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config(\"../../config.yaml\")\n",
    "\n",
    "print(f\"Model:\\n{cfg.model_name}\")\n",
    "\n",
    "os.environ[\"WANDB_ENTITY\"] = \"jonathanlehmkuhl-rwth-aachen-university\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"piano-transformer\"\n",
    "wandb.login()\n",
    "\n",
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be7fc9",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04e8c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train files: 962\n",
      "Number of validation files: 137\n",
      "Number of test files: 177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting music files (..\\..\\models\\mistral-162M_remi_maestro_v1\\data_processed\\maestro_train): 100%|██████████| 962/962 [00:11<00:00, 82.03it/s] \n",
      "Splitting music files (..\\..\\models\\mistral-162M_remi_maestro_v1\\data_processed\\maestro_validation): 100%|██████████| 137/137 [00:01<00:00, 101.13it/s]\n",
      "Splitting music files (..\\..\\models\\mistral-162M_remi_maestro_v1\\data_processed\\maestro_test): 100%|██████████| 177/177 [00:01<00:00, 110.46it/s]\n"
     ]
    }
   ],
   "source": [
    "midi_lists = get_midi_file_lists(cfg.data_raw_path / \"maestro\" / \"maestro-v3.0.0.csv\", cfg.data_raw_path / \"maestro\")\n",
    "\n",
    "for split in [\"train\", \"validation\", \"test\"]:\n",
    "    print(f\"Number of {split} files: {len(midi_lists[split])}\")\n",
    "\n",
    "tokenizer = create_remi_tokenizer(midi_lists[\"train\"], cfg.experiment_path / \"tokenizer.json\")\n",
    "\n",
    "MAX_SEQ_LEN = 2048\n",
    "NUM_OVERLAP_BARS = 16\n",
    "\n",
    "chunks_lists = split_datasets_into_chunks(midi_lists, tokenizer, cfg.data_processed_path, \"maestro\", MAX_SEQ_LEN, NUM_OVERLAP_BARS)\n",
    "\n",
    "augmentation_cfg = {\n",
    "    \"pitch_offsets\": list(range(-6, 6)),\n",
    "    \"velocity_offsets\": list(range(-20, 21)),\n",
    "    \"duration_offsets\": [-0.5, -0.375, -0.25, -0.125, 0, 0.125, 0.25, 0.375, 0.5],\n",
    "    \"tempo_factors\": [0.9, 0.925, 0.95, 0.975, 1.0, 1.025, 1.05, 1.075, 1.1],\n",
    "}\n",
    "\n",
    "\n",
    "train_ds, valid_ds, test_ds = build_datasets(chunks_lists, tokenizer, MAX_SEQ_LEN, augmentation_cfg)\n",
    "collator = build_collator(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb218c-9ead-4c2d-b9e5-28c0bfcd1f06",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cfg = {\n",
    "    \"num_hidden_layers\": 18,\n",
    "    \"hidden_size\": 512,\n",
    "    \"intermediate_size\": 512 * 8,\n",
    "    \"num_attention_heads\": 8,\n",
    "    \"attention_dropout\": 0.1,\n",
    "    \n",
    "} \n",
    "\n",
    "model = build_mistral_model(model_cfg, tokenizer, MAX_SEQ_LEN)\n",
    "\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "trainer_cfg = {\n",
    "    \"output_dir\": cfg.runs_path,\n",
    "    \"per_device_train_batch_size\": 64,\n",
    "    \"per_device_eval_batch_size\": 64,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"max_grad_norm\": 3.0,\n",
    "    \"lr_scheduler_type\": \"cosine_with_min_lr\",\n",
    "    \"min_lr_rate\": 0.1,\n",
    "    \"warmup_ratio\": 0.03,\n",
    "    \"logging_steps\": 20,\n",
    "    \"num_train_epochs\": 1000,\n",
    "    \"seed\": cfg.seed,\n",
    "    \"data_seed\": cfg.seed,\n",
    "    \"run_name\": cfg.model_name,\n",
    "    \"optim\": \"adamw_torch\",\n",
    "    \"early_stopping_patience\": 10,\n",
    "}\n",
    "\n",
    "trainer = make_trainer(trainer_cfg, model, collator, train_ds, valid_ds)\n",
    "\n",
    "result = trainer.train()\n",
    "trainer.save_model(cfg.model_path)\n",
    "trainer.log_metrics(\"train\", result.metrics)\n",
    "trainer.save_metrics(\"train\", result.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017e284-b7d1-4e23-a41c-51dbbe5145cf",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79d7de-b9d2-440e-8cb9-fb6320e4820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ee7d9-7a82-4dfb-83c5-7a17d3618e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    max_new_tokens=200,  # extends samples by 200 tokens\n",
    "    num_beams=1,\n",
    "    do_sample=True,\n",
    "    temperature=1,\n",
    "    top_k=15,\n",
    "    top_p=0.95,\n",
    "    epsilon_cutoff=3e-4,\n",
    "    eta_cutoff=1e-3,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Here the sequences are padded to the left, so that the last token along the time dimension\n",
    "# is always the last token of each seq, allowing to efficiently generate by batch\n",
    "collator.pad_on_left = True\n",
    "collator.eos_token = None\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d28fa-3a89-4721-8f4a-2d24a53dbb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(dataset, output):\n",
    "    (output_path := Path(output)).mkdir(parents=True, exist_ok=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, collate_fn=collator)\n",
    "    \n",
    "    count = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Generating outputs\"):\n",
    "        res = model.generate(\n",
    "            inputs=batch[\"input_ids\"].to(model.device),\n",
    "            attention_mask=batch[\"attention_mask\"].to(model.device),\n",
    "            generation_config=generation_config\n",
    "        )\n",
    "    \n",
    "        # Saves the generated music, as MIDI files and tokens (json)\n",
    "        for prompt, continuation in zip(batch[\"input_ids\"], res):\n",
    "            generated = continuation[len(prompt):]\n",
    "            tokens = [generated, prompt, continuation]\n",
    "            tokens = [seq.tolist() for seq in tokens]\n",
    "\n",
    "            midi_generated = tokenizer.decode([deepcopy(tokens[0])])\n",
    "            midi_prompt = tokenizer.decode([deepcopy(tokens[1])])\n",
    "            midi_full = tokenizer.decode([deepcopy(tokens[2])])\n",
    "\n",
    "            # Name the tracks\n",
    "            if midi_generated.tracks:\n",
    "                midi_generated.tracks[0].name = f\"Generated continuation ({len(tokens[0])} tokens)\"\n",
    "            if midi_prompt.tracks:\n",
    "                midi_prompt.tracks[0].name = f\"Original prompt ({len(tokens[1])} tokens)\"\n",
    "            if midi_full.tracks:\n",
    "                midi_full.tracks[0].name = f\"Full sequence ({len(tokens[2])} tokens)\"\n",
    "\n",
    "            # Save each as a separate MIDI file\n",
    "            midi_generated.dump_midi(output_path / f\"{count}_generated.midi\")\n",
    "            midi_prompt.dump_midi(output_path / f\"{count}_prompt.midi\")\n",
    "            midi_full.dump_midi(output_path / f\"{count}_full.midi\")\n",
    "            tokenizer.save_tokens(tokens, output_path / f\"{count}.json\")\n",
    "    \n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83091e-43d9-4e49-ba22-7e481f2b1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(dataset_test, OUTPUT_PATH / \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8de05-0295-439a-b278-291dbe231be4",
   "metadata": {},
   "source": [
    "## Convert to WAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d2d9b-47fc-42f0-b459-f8c0db84c07f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Song-000.MID to Song-000.wav...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# Build FluidSynth command\u001B[39;00m\n\u001B[32m     19\u001B[39m command = [\n\u001B[32m     20\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mfluidsynth\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     21\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m-ni\u001B[39m\u001B[33m\"\u001B[39m,  \u001B[38;5;66;03m# no interactive mode\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     25\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m-r\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m44100\u001B[39m\u001B[33m\"\u001B[39m    \u001B[38;5;66;03m# sample rate\u001B[39;00m\n\u001B[32m     26\u001B[39m ]\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m \u001B[43msubprocess\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcommand\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcheck\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Jonathan\\anaconda3\\envs\\dlab\\Lib\\subprocess.py:548\u001B[39m, in \u001B[36mrun\u001B[39m\u001B[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001B[39m\n\u001B[32m    545\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mstdout\u001B[39m\u001B[33m'\u001B[39m] = PIPE\n\u001B[32m    546\u001B[39m     kwargs[\u001B[33m'\u001B[39m\u001B[33mstderr\u001B[39m\u001B[33m'\u001B[39m] = PIPE\n\u001B[32m--> \u001B[39m\u001B[32m548\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpopenargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m process:\n\u001B[32m    549\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    550\u001B[39m         stdout, stderr = process.communicate(\u001B[38;5;28minput\u001B[39m, timeout=timeout)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Jonathan\\anaconda3\\envs\\dlab\\Lib\\subprocess.py:1026\u001B[39m, in \u001B[36mPopen.__init__\u001B[39m\u001B[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001B[39m\n\u001B[32m   1022\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.text_mode:\n\u001B[32m   1023\u001B[39m             \u001B[38;5;28mself\u001B[39m.stderr = io.TextIOWrapper(\u001B[38;5;28mself\u001B[39m.stderr,\n\u001B[32m   1024\u001B[39m                     encoding=encoding, errors=errors)\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_execute_child\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreexec_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1027\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mpass_fds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1028\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshell\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1029\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mp2cread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp2cwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1030\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mc2pread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc2pwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1031\u001B[39m \u001B[43m                        \u001B[49m\u001B[43merrread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrwrite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1032\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mrestore_signals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1033\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mgid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mumask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1034\u001B[39m \u001B[43m                        \u001B[49m\u001B[43mstart_new_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprocess_group\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1035\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[32m   1036\u001B[39m     \u001B[38;5;66;03m# Cleanup if the child failed starting.\u001B[39;00m\n\u001B[32m   1037\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mNone\u001B[39;00m, (\u001B[38;5;28mself\u001B[39m.stdin, \u001B[38;5;28mself\u001B[39m.stdout, \u001B[38;5;28mself\u001B[39m.stderr)):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mc:\\Users\\Jonathan\\anaconda3\\envs\\dlab\\Lib\\subprocess.py:1538\u001B[39m, in \u001B[36mPopen._execute_child\u001B[39m\u001B[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001B[39m\n\u001B[32m   1536\u001B[39m \u001B[38;5;66;03m# Start the process\u001B[39;00m\n\u001B[32m   1537\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1538\u001B[39m     hp, ht, pid, tid = \u001B[43m_winapi\u001B[49m\u001B[43m.\u001B[49m\u001B[43mCreateProcess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1539\u001B[39m \u001B[43m                             \u001B[49m\u001B[38;5;66;43;03m# no special security\u001B[39;49;00m\n\u001B[32m   1540\u001B[39m \u001B[43m                             \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1541\u001B[39m \u001B[43m                             \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclose_fds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1542\u001B[39m \u001B[43m                             \u001B[49m\u001B[43mcreationflags\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1543\u001B[39m \u001B[43m                             \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1544\u001B[39m \u001B[43m                             \u001B[49m\u001B[43mcwd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1545\u001B[39m \u001B[43m                             \u001B[49m\u001B[43mstartupinfo\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1546\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m   1547\u001B[39m     \u001B[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001B[39;00m\n\u001B[32m   1548\u001B[39m     \u001B[38;5;66;03m# handles that only the child should have open.  You need\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1551\u001B[39m     \u001B[38;5;66;03m# pipe will not close when the child process exits and the\u001B[39;00m\n\u001B[32m   1552\u001B[39m     \u001B[38;5;66;03m# ReadFile will hang.\u001B[39;00m\n\u001B[32m   1553\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001B[32m   1554\u001B[39m                          c2pread, c2pwrite,\n\u001B[32m   1555\u001B[39m                          errread, errwrite)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "soundfont_path = \"FluidR3_GM.sf2\"\n",
    "midi_folder = OUTPUT_PATH / \"test\"\n",
    "output_folder = OUTPUT_PATH / \"test_wav\"\n",
    "\n",
    "for filename in os.listdir(midi_folder):\n",
    "    if filename.lower().endswith(\".midi\"):\n",
    "        midi_path = os.path.join(midi_folder, filename)\n",
    "        wav_filename = os.path.splitext(filename)[0] + \".wav\"\n",
    "        wav_path = os.path.join(output_folder, wav_filename)\n",
    "        \n",
    "        print(f\"Converting {filename} to {wav_filename}...\")\n",
    "        \n",
    "        # Build FluidSynth command\n",
    "        command = [\n",
    "            \"fluidsynth\",\n",
    "            \"-ni\",  # no interactive mode\n",
    "            soundfont_path,\n",
    "            midi_path,\n",
    "            \"-F\", wav_path,  # output file\n",
    "            \"-r\", \"44100\"    # sample rate\n",
    "        ]\n",
    "        \n",
    "        subprocess.run(command, check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
